{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FashionMnist_Nishigandha_(21070149030).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOa2Ecs0-mOH"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "scL9j_Gs-pK3",
        "outputId": "7053c583-faa3-493a-d4e9-5c50102175a3"
      },
      "source": [
        "(trainX, trainY),(testX, testY)=tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VuQ2K6tl-2ab",
        "outputId": "c39882ed-a687-4971-e0f5-571b59a2d712"
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsV5xxps_RHA"
      },
      "source": [
        "Convert Output to Multiple Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGR4moUZ_W6l"
      },
      "source": [
        "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
        "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOXQNFx4_bzm"
      },
      "source": [
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AMqf5L2_kBb"
      },
      "source": [
        "#Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F9CIt7l_miq"
      },
      "source": [
        "#Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAnFjYKb_rcV"
      },
      "source": [
        "#Add Hidden Layer with 10 neurons\n",
        "model.add((tf.keras.layers.Dense(20, activation='relu')))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zQAe_Wa_xL6"
      },
      "source": [
        "#Add Hidden Layer with 40 neurons\n",
        "model.add((tf.keras.layers.Dense(40, activation='relu')))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPT8wwX3_1D4"
      },
      "source": [
        "\n",
        "#Add Hidden Layer with 10 neurons\n",
        "model.add((tf.keras.layers.Dense(20, activation='relu')))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Voh8Kv6o_3H-"
      },
      "source": [
        "\n",
        "#Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSN7_RX9_4RT"
      },
      "source": [
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lKbNZ2Pi_6QB",
        "outputId": "029d4fa9-3b93-4978-b48e-e75673775faf"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 784)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 784)              3136      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 20)                15700     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 40)                840       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 20)                820       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                210       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,706\n",
            "Trainable params: 19,138\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1Q-p_aQ2_9nC",
        "outputId": "61448c44-1efc-4feb-8108-099d59c65710"
      },
      "source": [
        "model.fit(trainX, trainY, validation_data=(testX, testY),epochs=100,batch_size=32)     "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.6783 - accuracy: 0.7596 - val_loss: 0.5178 - val_accuracy: 0.8187\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4679 - accuracy: 0.8312 - val_loss: 0.4541 - val_accuracy: 0.8402\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4273 - accuracy: 0.8448 - val_loss: 0.4362 - val_accuracy: 0.8495\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4049 - accuracy: 0.8520 - val_loss: 0.4138 - val_accuracy: 0.8550\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3899 - accuracy: 0.8576 - val_loss: 0.4098 - val_accuracy: 0.8543\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3792 - accuracy: 0.8618 - val_loss: 0.4062 - val_accuracy: 0.8591\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3707 - accuracy: 0.8641 - val_loss: 0.4015 - val_accuracy: 0.8615\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3611 - accuracy: 0.8682 - val_loss: 0.3992 - val_accuracy: 0.8614\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3546 - accuracy: 0.8712 - val_loss: 0.4076 - val_accuracy: 0.8605\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3498 - accuracy: 0.8717 - val_loss: 0.3827 - val_accuracy: 0.8656\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3420 - accuracy: 0.8750 - val_loss: 0.3914 - val_accuracy: 0.8648\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3360 - accuracy: 0.8757 - val_loss: 0.3886 - val_accuracy: 0.8642\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3321 - accuracy: 0.8776 - val_loss: 0.3859 - val_accuracy: 0.8668\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3307 - accuracy: 0.8786 - val_loss: 0.3767 - val_accuracy: 0.8684\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3241 - accuracy: 0.8813 - val_loss: 0.3961 - val_accuracy: 0.8675\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3192 - accuracy: 0.8820 - val_loss: 0.3697 - val_accuracy: 0.8706\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3173 - accuracy: 0.8829 - val_loss: 0.3783 - val_accuracy: 0.8721\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3160 - accuracy: 0.8829 - val_loss: 0.3794 - val_accuracy: 0.8707\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3120 - accuracy: 0.8849 - val_loss: 0.3673 - val_accuracy: 0.8742\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3127 - accuracy: 0.8850 - val_loss: 0.3769 - val_accuracy: 0.8679\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3078 - accuracy: 0.8850 - val_loss: 0.3751 - val_accuracy: 0.8770\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3081 - accuracy: 0.8858 - val_loss: 0.3666 - val_accuracy: 0.8743\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3026 - accuracy: 0.8892 - val_loss: 0.3656 - val_accuracy: 0.8757\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3045 - accuracy: 0.8862 - val_loss: 0.3831 - val_accuracy: 0.8740\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3007 - accuracy: 0.8892 - val_loss: 0.3757 - val_accuracy: 0.8752\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2958 - accuracy: 0.8906 - val_loss: 0.3686 - val_accuracy: 0.8752\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2980 - accuracy: 0.8891 - val_loss: 0.3982 - val_accuracy: 0.8762\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2947 - accuracy: 0.8912 - val_loss: 0.3927 - val_accuracy: 0.8730\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2905 - accuracy: 0.8927 - val_loss: 0.3765 - val_accuracy: 0.8731\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2916 - accuracy: 0.8926 - val_loss: 0.3662 - val_accuracy: 0.8744\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2902 - accuracy: 0.8924 - val_loss: 0.3649 - val_accuracy: 0.8724\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2899 - accuracy: 0.8925 - val_loss: 0.4040 - val_accuracy: 0.8782\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2854 - accuracy: 0.8927 - val_loss: 0.3908 - val_accuracy: 0.8749\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2862 - accuracy: 0.8937 - val_loss: 0.3548 - val_accuracy: 0.8775\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2843 - accuracy: 0.8943 - val_loss: 0.3764 - val_accuracy: 0.8731\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2828 - accuracy: 0.8951 - val_loss: 0.3702 - val_accuracy: 0.8733\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2805 - accuracy: 0.8958 - val_loss: 0.3717 - val_accuracy: 0.8800\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2810 - accuracy: 0.8947 - val_loss: 0.3591 - val_accuracy: 0.8767\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2795 - accuracy: 0.8956 - val_loss: 0.3832 - val_accuracy: 0.8755\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2773 - accuracy: 0.8976 - val_loss: 0.3825 - val_accuracy: 0.8759\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2784 - accuracy: 0.8956 - val_loss: 0.3911 - val_accuracy: 0.8762\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2747 - accuracy: 0.8988 - val_loss: 0.3754 - val_accuracy: 0.8760\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2776 - accuracy: 0.8963 - val_loss: 0.3841 - val_accuracy: 0.8804\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2733 - accuracy: 0.8985 - val_loss: 0.3745 - val_accuracy: 0.8774\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2708 - accuracy: 0.8995 - val_loss: 0.4346 - val_accuracy: 0.8783\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2701 - accuracy: 0.9000 - val_loss: 0.3661 - val_accuracy: 0.8719\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2706 - accuracy: 0.9004 - val_loss: 0.4075 - val_accuracy: 0.8760\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2666 - accuracy: 0.9011 - val_loss: 0.3697 - val_accuracy: 0.8766\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2699 - accuracy: 0.9004 - val_loss: 0.3792 - val_accuracy: 0.8785\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2671 - accuracy: 0.9004 - val_loss: 0.3648 - val_accuracy: 0.8785\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2674 - accuracy: 0.9013 - val_loss: 0.3652 - val_accuracy: 0.8761\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2668 - accuracy: 0.9007 - val_loss: 0.3966 - val_accuracy: 0.8762\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2663 - accuracy: 0.9010 - val_loss: 0.3788 - val_accuracy: 0.8747\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2642 - accuracy: 0.9007 - val_loss: 0.3757 - val_accuracy: 0.8773\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2655 - accuracy: 0.9016 - val_loss: 0.3716 - val_accuracy: 0.8773\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2606 - accuracy: 0.9045 - val_loss: 0.3892 - val_accuracy: 0.8738\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2646 - accuracy: 0.9022 - val_loss: 0.3918 - val_accuracy: 0.8766\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2612 - accuracy: 0.9025 - val_loss: 0.3998 - val_accuracy: 0.8771\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2614 - accuracy: 0.9027 - val_loss: 0.4100 - val_accuracy: 0.8787\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2612 - accuracy: 0.9032 - val_loss: 0.3787 - val_accuracy: 0.8793\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2599 - accuracy: 0.9036 - val_loss: 0.4125 - val_accuracy: 0.8758\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2573 - accuracy: 0.9046 - val_loss: 0.3773 - val_accuracy: 0.8737\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2582 - accuracy: 0.9033 - val_loss: 0.3730 - val_accuracy: 0.8771\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2571 - accuracy: 0.9039 - val_loss: 0.4166 - val_accuracy: 0.8750\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2563 - accuracy: 0.9032 - val_loss: 0.4109 - val_accuracy: 0.8760\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2588 - accuracy: 0.9025 - val_loss: 0.3768 - val_accuracy: 0.8764\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2573 - accuracy: 0.9033 - val_loss: 0.4339 - val_accuracy: 0.8771\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2574 - accuracy: 0.9036 - val_loss: 0.3700 - val_accuracy: 0.8791\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2535 - accuracy: 0.9064 - val_loss: 0.3981 - val_accuracy: 0.8783\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2557 - accuracy: 0.9035 - val_loss: 0.3633 - val_accuracy: 0.8773\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2509 - accuracy: 0.9057 - val_loss: 0.4290 - val_accuracy: 0.8779\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2516 - accuracy: 0.9062 - val_loss: 0.3766 - val_accuracy: 0.8796\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2544 - accuracy: 0.9052 - val_loss: 0.3823 - val_accuracy: 0.8745\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2500 - accuracy: 0.9067 - val_loss: 0.4365 - val_accuracy: 0.8798\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2529 - accuracy: 0.9059 - val_loss: 0.3790 - val_accuracy: 0.8776\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2490 - accuracy: 0.9082 - val_loss: 0.4129 - val_accuracy: 0.8774\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2505 - accuracy: 0.9071 - val_loss: 0.3681 - val_accuracy: 0.8774\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2504 - accuracy: 0.9069 - val_loss: 0.4436 - val_accuracy: 0.8772\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2516 - accuracy: 0.9072 - val_loss: 0.3903 - val_accuracy: 0.8774\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2470 - accuracy: 0.9075 - val_loss: 0.3784 - val_accuracy: 0.8753\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2476 - accuracy: 0.9087 - val_loss: 0.3999 - val_accuracy: 0.8778\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2483 - accuracy: 0.9074 - val_loss: 0.3906 - val_accuracy: 0.8735\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2468 - accuracy: 0.9075 - val_loss: 0.4442 - val_accuracy: 0.8760\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2463 - accuracy: 0.9083 - val_loss: 0.3935 - val_accuracy: 0.8749\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2440 - accuracy: 0.9088 - val_loss: 0.3959 - val_accuracy: 0.8754\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2480 - accuracy: 0.9071 - val_loss: 0.4189 - val_accuracy: 0.8763\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2472 - accuracy: 0.9069 - val_loss: 0.4222 - val_accuracy: 0.8737\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2452 - accuracy: 0.9093 - val_loss: 0.3807 - val_accuracy: 0.8778\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2469 - accuracy: 0.9087 - val_loss: 0.4037 - val_accuracy: 0.8758\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2455 - accuracy: 0.9083 - val_loss: 0.4090 - val_accuracy: 0.8763\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2443 - accuracy: 0.9085 - val_loss: 0.4298 - val_accuracy: 0.8751\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2431 - accuracy: 0.9096 - val_loss: 0.3834 - val_accuracy: 0.8797\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2429 - accuracy: 0.9098 - val_loss: 0.4064 - val_accuracy: 0.8772\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2425 - accuracy: 0.9096 - val_loss: 0.3966 - val_accuracy: 0.8729\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2425 - accuracy: 0.9097 - val_loss: 0.4030 - val_accuracy: 0.8775\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2422 - accuracy: 0.9090 - val_loss: 0.4123 - val_accuracy: 0.8721\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2408 - accuracy: 0.9093 - val_loss: 0.3988 - val_accuracy: 0.8781\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2390 - accuracy: 0.9109 - val_loss: 0.4085 - val_accuracy: 0.8791\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2419 - accuracy: 0.9094 - val_loss: 0.4268 - val_accuracy: 0.8734\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2395 - accuracy: 0.9108 - val_loss: 0.4135 - val_accuracy: 0.8743\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2e947213d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}